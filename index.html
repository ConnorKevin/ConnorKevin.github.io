<!DOCTYPE html>
<html>

<head>
<title>Kenan Li</title>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<style>
	body {
		font: 14px/1.5 -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
		padding-left: 10%;
		padding-right: 10%;
	}

	papertitle {
	            font-size: 16px;
	            font-weight: bold;
	            color: #333;
	            display: block;
	            margin-bottom: 4px;
	}
	
	header {
		border-bottom: 1px solid gray;
		text-align: center;
	}

	nav {
	    float: left;
	    padding-top: 3%;
	    display: block;
	}

	article {
		overflow: hidden;
		padding-left: 5%;
	}

	a:link, a:visited {
		color: #047DF2;/*#2da38d;#356d63;#3a8c7d;*/
		text-decoration: none;
	}

	strong {
	font-family: Lora;
	font-size: 16px;
	font-weight: 600;
        }

	ul {
	list-style-position: outside;
        }
	/* li{
	list-style:none;
	        table img {
            width: 100%;
            height: auto;
        }*/

        @media (max-width: 768px) {
            table {
                width: 100%;
            }
            
            table td {
                display: block;
                width: 100%;
            }
	}
	.more-authors {
            display: none; /* 默认隐藏详细作者列表 */
        }
        .show-authors {
            display: inline; /* 控制详细作者列表显示 */
        }
        .toggle-link {
            color: #047DF2;
            text-decoration: underline;
	    text-decoration-style: dashed;
            cursor: pointer;
        }



</style>
</head>

<body>
    <div height="40" id="header" style="background-color:#002FA7; color: #002FA7">
      <center>
        <table width="1050" height="40" border="0">
          <tr>
		<td halign="center">
			<p align="center"><font size="6"><font color=#FFFFFF>Kenan Li (李克难)</font> </p>
		</td>
	</tr>
        </table>
      </center>
    </div>
	
	
<!-- 	<header class="header">
	  <h1>Kenan Li (李克难)</h1>
	</header> -->

	<nav class="nav">
		<center>
<!-- 			<a href="map.html"> -->
			<img src="files/likenan.jpg" style="height:200px;"></a>
		</center>
		<ul class="fa-ul">
			<li><i class="fa-li fa fa-envelope"></i>
				<a href="mailto:kevin.connor.lee@gmail.com" style="text-decoration: none">Email</a>
			</li>
			
			<li><i class="fa-li fa fa-github"></i>
				<a href="https://github.com/ConnorKevin" style="text-decoration: none">Github</a>
			</li>
			
			<!-- <li><i class="fa-li fa fa-book"></i>
				<a href="https://scholar.google.com/citations?user=WvdVTmIAAAAJ&hl=en" style="text-decoration: none">Google Scholar</a>
			</li> -->
			
			<li><i class="fa-li fa fa-file"></i><a href="files/KLCV_Shorted_IROS.pdf">Resume</a>
			</li>
		</ul>
	</nav>

	<article class="article">
		<h1>About Me</h1>
		<p> I am currently a research assistant in <a href="https://group.iiis.tsinghua.edu.cn/~marslab/#/">MARS Lab</a> at Tsinghua University, working under the supervision of <a href="https://hangzhaomit.github.io/">Prof. Hang Zhao</a>. Since April 2023, I have also been collaborating closely with <a href="https://yimingli-page.github.io/">Yiming Li</a>, under the supervision of <a href="https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en">Prof. Chen Feng</a> at <a href="https://ai4ce.github.io/">NYU AI4CE Lab</a>. I got my master's degree in the Electronic Engineering at Southern University of Science and Technology (SUSTech) 
<!-- 			under the supervision of <a href="https://www.sustech.edu.cn/en/faculties/hongxiaoping.html">Prof. Xiaoping Hong</a> and <a href="https://www.hkust-gz.edu.cn/people/wu-jingshen/">Prof. Jingshen Wu.</a><br/> -->
			under the supervision of <a href="https://www.researchgate.net/profile/Xiaoping-Hong">Prof. Xiaoping Hong</a> / <a href="https://baike.baidu.com/item/%E6%B4%AA%E5%B0%8F%E5%B9%B3/56787731">CN</a> and <a href="https://www.hkust-gz.edu.cn/people/wu-jingshen/">Prof. Jingshen Wu.</a>
			I received a B.S. in Electrical Engineering at North China Electric Power University (NCEPU).<br/>
			<p>
			I have a strong passion for building intelligent robots and novel HCI systems.
			</p>
			<p>
			Through robotics research, I seek to understand intelligence by creating systems that can sense, reason, and act in complex environments.
			</p>
		<!-- <p><i> "Nothing in life is to be feared; it is only to be understood."</i>  --Marie Curie </p> -->
		<p><i> "What I cannot create, I do not understand."</i>  --Richard Feynman </p>
		

		

                   <h1>Publications</h1>
                       (*Equal contribution, †Corresponding authors)

				<table width="100%" border="0" align="top" cellpadding="10">
			   <tr>
			   <td width="20%" valign="center">
			   <img src="files/complet4RS.png" alt="" width="100%" class="border">
			   </td> 
			   <td width="80%" valign="center">
			   <papertitle>Complet4R: Geometric Complete 4D Reconstruction</papertitle>
			   <a style="color : #000000;">Complet4R reconstructs a complete geometry for every time step with all observations in one sequence, including occluded regions visible in other frames.</a><br/>

			   <a style="color : #000000;">Weibang Wang*</a>,
			   <a style="color : #000000;"><strong>Kenan Li*</strong></a>,
			   <a style="color : #000000;">Zhuoguang Chen*</a>,				   
			   <a style="color : #000000;">Yijun Yuan†</a>,
			   <a style="color : #000000;">Hang Zhao†</a><br/>
			   <i> IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2026 </i><br/> 
			   </td>
			   </tr>
			   </table>








		
				<table width="100%" border="0" align="top" cellpadding="10">
			   <tr>
			   <td width="20%" valign="center">
			   <img src="files/SLAMFormerS.png" alt="" width="100%" class="border">
			   </td> 
			   <td width="80%" valign="center">
			   <papertitle>SLAM-Former: Putting SLAM into One Transformer</papertitle>
			   <a style="color : #000000;">We present SLAM-Former, a novel neural approach that integrates full SLAM capabilities into a single transformer </a><br/>
			   <a style="color : #000000;">Yijun Yuan</a>,
			   <a style="color : #000000;">Zhuoguang Chen</a>,
			      <a style="color : #000000;"><strong>Kenan Li</strong></a>,
			   <a style="color : #000000;">Weibang Wang</a>,
			   <a style="color : #000000;">Minghui Qin</a>,
			   <a style="color : #000000;">Hang Zhao†</a><br/>
			   <i> arXiv preprint arXiv:2509.16909 </i><br/> 
			   <a href="https://arxiv.org/pdf/2509.16909">arXiv</a>
			   <a href="https://tsinghua-mars-lab.github.io/SLAM-Former/">Web</a>
			   <a href="https://github.com/Tsinghua-MARS-Lab/SLAM-Former">Github</a>
			   
			   </td>
			   </tr>
			   </table>

		
		
                   <table width="100%" border="0" align="top" cellpadding="10">
			<tr>
			<td width="20%" valign="center">
			<img src="files/TrackOccSuburban.gif" alt="" width="100%" class="border">
			</td> 
			<td width="80%" valign="center">
			<papertitle>TrackOcc: Camera-based 4D Panoptic Occupancy Tracking</papertitle>
<!-- 			<a style="color : #000000;">We make the first attempt to explore a camera-based 4D panoptic occupancy tracking task and use 4D panoptic queries to achieve SOTA on Waymo Dataset in a streaming, end-to-end manner. Localization-aware loss is also proposed to enhance the tracking performance</a><br/> -->
			<a style="color : #000000;">Zhuoguang Chen*</a>,
		        <a style="color : #000000;"><strong>Kenan Li*</strong></a>,
			<a style="color : #000000;">Xiuyu Yang</a>,
			<a style="color : #000000;">Tao Jiang</a>,
			<a style="color : #000000;">Yiming Li</a>,
			<a style="color : #000000;">Hang Zhao†</a><br/>
			<i> IEEE International Conference on Robotics and Automation (ICRA), 2025</i><br/>	
			<a href="files/TrackOcc_ICRA2025.pdf">Paper</a>
			<a href="https://arxiv.org/abs/2503.08471">arXiv</a>
			<a href="https://github.com/Tsinghua-MARS-Lab/TrackOcc">Github</a>
			
			</td>
			</tr>
			</table>

		
                   <table width="100%" border="0" align="top" cellpadding="10">
			<tr>
			<td width="20%" valign="center">
			<img src="files/SSCBench.gif" alt="" width="100%" class="border">
			</td> 
			<td width="80%" valign="center">
			<papertitle>SSCBench: Monocular 3D Semantic Scene Completion Benchmark in Street Views</papertitle>
<!-- 			<a style="color : #000000;">We present quantitative and qualitative evaluations of state-of-the-art algorithms on SSCBench and commit to continuously incorporating novel automotive datasets and SSC (Semantic Scene Completion) algorithms to drive further advancements in this field.</a><br/> -->
<!-- 			<a style="color : #000000;">Yiming Li</a>,
		        <a style="color : #000000;">Sihang Li</a>,
			<a style="color : #000000;">Xinhao Liu</a>,
			<a style="color : #000000;">Moonjun Gong</a>,
			<a style="color : #000000;"><strong>Kenan Li</strong></a>, -->
			<p>
				<span>Yiming Li*, Sihang Li*, Xinhao Liu*, Moonjun Gong*, <strong>Kenan Li</strong>, </span>
				<span class="more-authors">Nuo Chen, Zijun Wang, Zhiheng Li, Tao Jiang, Fisher Yu, Yue Wang, Hang Zhao, Zhiding Yu, Chen Feng†</span>
				<span class="toggle-link" onclick="toggleAuthors(this)">9 more authors</span>
			</p>
			<a style="color : #000000;"><i>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2024 </i></a><br/>
			<a href="https://arxiv.org/abs/2306.09001">Paper</a>
			<a href="https://github.com/ai4ce/SSCBench">Github</a>
			</td>
			</tr>
			</table>

		
	        <table width="100%" border="0" align="top" cellpadding="10">
		    <tr>
		    <td width="20%" valign="center">
		    <img src="files/LaserMic.jpg" alt="" width="100%" class="border">
		    </td> 
		    <td width="80%" valign="center">
		    <papertitle>Robot Hearing Through Optical Channel in a Cocktail Party Environment</papertitle>
		        <a style="color : #000000;">Xiao Guo*</a>,
		        <a style="color : #000000;">Siyi Ding*</a>,
			<a style="color : #000000;">Ti Peng</a>,
			<a style="color : #000000;"><strong>Kenan Li</strong></a>,
			<a style="color : #000000;">Xiaoping Hong†</a><br/>	    
	        <a style="color : #000000;"> <i>Advanced Intelligent Systems (2023)</i></a><br/>
			<a href="https://onlinelibrary.wiley.com/doi/10.1002/aisy.202200143">Paper</a>
		    </td>
		    </tr>
		</table>	
		
		<h1>Selected Projects</h1>
			
		<table width="100%" border="0" align="top" cellpadding="10">
			<tr>
			<td width="20%" valign="center">
			<img src="files/KaggleBirds.jpg" alt="" width="100%" class="border">
			</td> 
			<td width="80%" valign="center">
			<papertitle>Identify Bird Calls in Soundscapes</papertitle>
			<a style="color : #000000;">Designed and implemented a classification algorithm used densenet121, to classify the bird sound in correct category.</a><br/>
			<a style="color : #000000;"><strong>Kenan Li</strong></a><br/>
			<a href="https://www.kaggle.com/competitions/birdclef-2022/leaderboard">Kaggler: Kevin Connor</a>
			</td>
			</tr>
		</table>
				

		    <table width="100%" border="0" align="top" cellpadding="10">
			<tr>
			<td width="20%" valign="center">
			<img src="files/RoboHusky.jpg" alt="" width="100%" class="border">
			</td> 
			<td width="80%" valign="center">
			<papertitle>RobotHusky-Field Agriculture Robot</papertitle>
			<a href="", style="color : #000000;">As part of the robot project, we use a classification algorithm based on VGG-16 to identify the maize and grass. We collected the pictures of maize in the field and augmented the data set with flip, rotate and scale, tried several ways, and finally decided to use the result with 89% precision based on the VGGNet.</a><br/>
			<a href="https://github.com/Galaxy-Motion/RobotHusky">Project Github</a>
			</td>
			</tr>
		    </table>	

		<h1>Patents</h1>
		<ul>
			<li>
				CN202111111240.5 (In process), "一种光学麦克风系统及其收音方法".
			</li>
<!-- 			<li>
				CN202110769621.6 (In process), "一种皮带廊巡检机器人".
			</li> -->
	       </ul>
		<h1>Honors & Awards</h1>
		<ul>
			<h2>Honors & Scholarship</h2>

			<li>
			<div style="float:left; text-align:left">3rd Prize, Excellent Teaching Assistant</div>
			<div style="float:right; text-align:right">2021</div>
			</li>
			<li>
			<div style="float:left; text-align:left">Scholarship, Southern University of Science and Technology</div>
			<div style="float:right; text-align:right">2019</div>
			</li>
			<li>
			<div style="float:left; text-align:left">Excellent Coach</div>
			<div style="float:right; text-align:right">2019</div>
			</li>
			<li>
			<div style="float:left; text-align:left"> Outstanding Graduates in NCEPU</div>
			<div style="float:right; text-align:right">2019</div>
			</li>
			<li>
			<div style="float:left; text-align:left">Siyuan Electric Power Scholarship</div>
			<div style="float:right; text-align:right">2018</div>
			</li>
			<li>
			<div style="float:left; text-align:left">Advanced Individual of Innovation and Entrepreneurship</div>
			<div style="float:right; text-align:right"> 2017, 2018</div>
			</li>		
			<li>
			<div style="float:left; text-align:left">2nd Prize, Scholarship; Merit Student in NCEPU</div>
			<div style="float:right; text-align:right">2016, 2017, 2018</div>
			</li>
			
			<h2>Competition Awards</h2>

			<li>
			<div style="float:left; text-align:left">Bronze Medal(11%), Kaggle Data Science Competition: BirdCLEF 2022</div>
			<div style="float:right; text-align:right">2022</div>
			</li>							
			<li style="clear:both">
			<div style="float:left; text-align:left">National Class, Rated Excellent, College students' innovation & entrepreneurship training program</div>
			<div style="float:right; text-align:right">2018</div>
		        </li>	
			<li>
			<div style="float:left; text-align:left">Provincial 2nd Prize, China Undergraduate Mathematical Contest in Modelling</div>
			<div style="float:right; text-align:right">2018</div>
			</li>
			<li>
			<div style="float:left; text-align:left">National 3rd Prize, 2017 China Robot Competition (FIRA Simulation Group)</div>
			<div style="float:right; text-align:right">2017</div>
			</li>
			<li>
			<div style="float:left; text-align:left">Provincial 3rd Prize, Hebei College Students Internet+ Innovation & Entrepreneurship Competition</div>
			<div style="float:right; text-align:right">2017</div>
			</li>
			<li style="clear:both">
			<div style="float:left; text-align:left">National 2nd Prize, Bridge+ (National Youth Business Simulation Contest)</div>
			<div style="float:right; text-align:right">2016</div>
			</li>
	    </ul>
	    <h1>Teaching</h1>
	    <ul>
			<li>
			<div style="float:left; text-align:left"><a href="https://course-tao.sustech.edu.cn/kcxxweb/queryKcxxwebDetailVisitorEnglishPC?pkcdm=SDM242">SDM242 Analog and System Design, Teaching Asistent</a></div>
			<div style="float:right; text-align:right">Fall, 2020-2021</div>
			<p style="clear:both; text-align:left; padding-left:15px;">This course covers the fundamentals of analog circuit design, including hands-on projects and real-world applications. 16 weeks for 33 undergraduates, created an SOP, tutored the lab, and coded a system that can automatically
summarize the scores from graders and distribute them by email.</p>
			</li>
			<li>
			<div style="float:left; text-align:left"><a href="https://newshub.sustech.edu.cn/en/html/201908/15419.html">SUSTech Da Vinci Challenge Camp, Coach</a></div>
			<div style="float:right; text-align:right">Summer, 2019</div>
			<p style="clear:both; text-align:left; padding-left:15px;">Coached the undergraduates in 5 people group in new engineering education camp for around 40 days.</p>	
			</li>
	    </ul>
	      
			
	</article>
	<script>
	        function toggleAuthors(element) {
	            const moreAuthors = element.previousElementSibling;
	            moreAuthors.classList.toggle('more-authors');
	            
	            // 如果详细作者列表现在是显示状态，修改按钮文字
		    if (moreAuthors.classList.contains('show-authors')) {
		        element.textContent = "Show less";
		    } else {
		        element.textContent = "6 more authors";
		    }
	        }
       </script>
</body>
</html> 
